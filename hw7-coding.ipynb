{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "palestinian-burst",
   "metadata": {},
   "source": [
    "# <center> Homework 7: Support Vector Machines </center>\n",
    "<center> Anushna Prakash </center>\n",
    "<center> May 28, 2021 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-purse",
   "metadata": {},
   "source": [
    "$$ \\min_{\\alpha \\in \\mathbb{R}^n} F(\\alpha):= \\frac{1}{n} \\sum_{i=1}^{n} \\ell(y_i, (K\\alpha)_i) + \\lambda \\alpha^T K \\alpha$$  \n",
    "$$ \\min_{\\alpha \\in \\mathbb{R}^n} F(\\alpha):= \\frac{1}{n} \\sum_{i=1}^{n} (\\max \\{0, 1 - y_i (K\\alpha)_i\\})^2 + \\lambda \\alpha^T K \\alpha$$  \n",
    "$$ \\nabla F(\\alpha) = -\\frac{2}{n} \\sum_{i=1}^{n} K_i y_i  \\max \\{0, 1-y_i K_i^T \\alpha\\} + 2\\lambda K \\alpha $$  \n",
    "$$\n",
    "    \\nabla F(\\alpha) = \n",
    "    \\begin{cases}\n",
    "        -\\frac{2}{n} \\sum_{i=1}^{n} K_i y_i (1 - y_i K_i^T \\alpha) + 2 \\lambda K \\alpha, & \\text{for } 1-y_i(K\\alpha)_i > 0\\\\\n",
    "        2 \\lambda K \\alpha, & \\text{for } 1-y_i(K\\alpha)_i <= 0\\\\\n",
    "    \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plastic-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "proved-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernal(x, y, b, p):\n",
    "    return ((x @ y.T) + b)**p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "complicated-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computegram(k, x, b, p):\n",
    "#     n = x.shape[0]\n",
    "#     K = np.empty(shape = (n, n))\n",
    "    \n",
    "    K = k(x, x, b, p)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "interstate-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernaleval(k, x, x_star, b, p):\n",
    "    kernal_evals = k(x, x_star, b, p)\n",
    "    \n",
    "    return kernal_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "little-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_f(alpha, gram, X, y, lambda_):\n",
    "    n = X.shape[0]\n",
    "    K_a = np.dot(gram, alpha)\n",
    "#     loss = 0\n",
    "#     for i in range(n):\n",
    "#         cond = 1.0 - y[i] * K_a[i]\n",
    "#         if cond > 0:\n",
    "#             loss += np.square(cond)\n",
    "    loss = 1.0 - np.multiply(y, K_a)\n",
    "    loss_condition = np.where(loss > 0, loss, 0)\n",
    "\n",
    "    return np.mean(np.square(loss_condition)) + lambda_ * (alpha.T @ gram @ alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "absent-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_grad(alpha, gram, X, y, lambda_):\n",
    "    n = len(X)\n",
    "    K_a = np.dot(gram, alpha)\n",
    "    loss_condition = 1.0 - np.multiply(y, np.dot(gram, alpha))\n",
    "    reg = 2.0 * lambda_ * K_a\n",
    "    loss_delta = -2 * y * gram\n",
    "    loss = np.where(loss_condition > 0, loss_condition, 0)\n",
    "    loss_grad = loss_delta * loss\n",
    "    \n",
    "#     for i in range(n):\n",
    "#         if loss[i] > 0:\n",
    "#             K_y = gram[i] * y[i]\n",
    "#             loss_grad += -2 * K_y * loss[i]\n",
    "        \n",
    "    return (1/n) * np.sum(loss_grad, axis = 1) + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "compact-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(eta_init, decay_rate, prop_constant, alpha, *args):\n",
    "    eta = eta_init\n",
    "    \n",
    "    def decrease_condition(eta):\n",
    "        grad = svm_grad(alpha, *args)\n",
    "        left = svm_f(alpha - eta * grad, *args) - svm_f(alpha, *args)\n",
    "        right = -eta * prop_constant * np.linalg.norm(grad)**2\n",
    "        return left <= right\n",
    "    \n",
    "    while not decrease_condition(eta):\n",
    "        eta *= decay_rate\n",
    "    \n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "unnecessary-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysvm(eta_init, tol, alpha_init, *args):\n",
    "    theta = alpha_init.copy()\n",
    "    alpha = alpha_init.copy()\n",
    "    iters = [alpha]\n",
    "    grad = svm_grad(alpha, *args)\n",
    "    decay_rate = 0.3\n",
    "    prop_constant = 0.3\n",
    "    t = 0\n",
    "    \n",
    "    while np.linalg.norm(grad) > tol:\n",
    "#         print(grad)\n",
    "        eta = backtracking(eta_init, decay_rate, prop_constant, theta, *args)\n",
    "        alpha_t = theta - eta * svm_grad(theta, *args)\n",
    "        theta = alpha_t + (t/(t + 3)) * (alpha_t - alpha)\n",
    "        grad = svm_grad(alpha_t, *args)\n",
    "        iters.append(alpha_t)\n",
    "        alpha = alpha_t\n",
    "        t += 1\n",
    "    \n",
    "    return iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "refined-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "digits = load_digits().data\n",
    "y = load_digits().target\n",
    "\n",
    "# Normalize and split 80/20 training and test\n",
    "digits = normalize(digits, norm = 'l2', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits, y, train_size = 0.8, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "initial-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = np.unique(y)\n",
    "classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bibliographic-intake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f35d5342610>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta_init = 0.000001\n",
    "tol = 1.0\n",
    "alpha_init = np.zeros(X_train.shape[0])\n",
    "lam = 10.0\n",
    "B = 1\n",
    "P = 7\n",
    "K = computegram(kernal, X_train, B, P)\n",
    "\n",
    "plt.figure(figsize = (8, 5))\n",
    "for d in digits:\n",
    "    # train a classifier on y_i^d = 1 if y_i = d, -1 else\n",
    "    colors = {0: 'cornflowerblue', 1: 'chocolate', 2: 'seagreen', 3: 'indianred', 4: 'gold',\n",
    "              5: 'purple', 6: 'saddlebrown', 7: 'teal', 8: 'lightpink', 9: 'slategrey'}\n",
    "    y_train_d = np.where(y_train == d, 1, -1)\n",
    "    svm_d = mysvm(eta_init, tol, alpha_init, K, X_train, y_train_d, lam)\n",
    "    classifiers[d] = svm_d[-1]\n",
    "    obj = [svm_f(a, K, X_train, y_train_d, lam) for a in svm_d]\n",
    "    plt.plot(obj, c = colors[d])\n",
    "\n",
    "plt.title('SVM Objective vs. Iterations')\n",
    "plt.legend(labels = digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "frank-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(truth, preds):\n",
    "    return np.mean(truth == preds)\n",
    "\n",
    "def preds_kernal(alpha, x, x_star, *args):\n",
    "    preds = alpha @ kernaleval(kernal, x, x_star, *args)\n",
    "    \n",
    "    return np.where(preds > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a4313da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9138888888888889"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_0 = np.where(y_test == 0, 1, -1)\n",
    "preds = preds_kernal(classifiers[0], X_train, X_test, B, P)\n",
    "accuracy(y_0, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8cfda09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_indices(n, K, j):\n",
    "    fold_size = n // K\n",
    "    \n",
    "    idx = np.arange(n)\n",
    "    val_idx = idx[j * fold_size : (j+1) * fold_size]\n",
    "    \n",
    "    if j == 0: \n",
    "        train_idx = idx[fold_size : n]\n",
    "    elif j == K-1:\n",
    "        train_idx = idx[0 : (K-1) * fold_size]\n",
    "    else:\n",
    "        first_range = idx[0 : j * fold_size]\n",
    "        second_range = idx[(j+1) * fold_size : n]\n",
    "        train_idx = np.concatenate((first_range, second_range))\n",
    "    \n",
    "    return train_idx, val_idx\n",
    "\n",
    "def K_fold_cross_validation(folds, digit, lambdas, X, y):\n",
    "    \n",
    "    n = len(X)\n",
    "    best_lambda = None\n",
    "    best_performance = 0.0\n",
    "    y_d = np.where(y == digit, 1, -1)\n",
    "    eta_init = 1e-6\n",
    "    tol = 1.0\n",
    "    B = 1\n",
    "    P = 7\n",
    "        \n",
    "    for i, lam in enumerate(lambdas):\n",
    "        \n",
    "        print(\"---------------------------------------------------\")\n",
    "        print(\"Evaluating lambda =\", lam, end=\"\")\n",
    "        \n",
    "        accuracies = np.zeros(folds)\n",
    "        for j in range(folds):\n",
    "            \n",
    "            print(\".\", end=\"\")\n",
    "            \n",
    "            # Subset into training and validation set.\n",
    "            train_idx, val_idx = get_fold_indices(n, folds, j)\n",
    "            X_train, y_train = X[train_idx], y_d[train_idx]\n",
    "            X_val, y_val = X[val_idx], y_d[val_idx]\n",
    "            \n",
    "            # Train on the training set.\n",
    "            gram = computegram(kernal, X_train, B, P)\n",
    "            a_init = np.zeros(X_train.shape[0])\n",
    "            alpha = mysvm(eta_init, tol, a_init, gram, X_train, y_train, lam)[-1]\n",
    "            \n",
    "            # Evaluate on the validation set.\n",
    "            \n",
    "            val_preds = preds_kernal(alpha, X_train, X_val, B, P)\n",
    "            accuracies[j] = accuracy(y_val, val_preds)\n",
    "        \n",
    "        performance = np.mean(accuracies)\n",
    "        print(\"\")\n",
    "        print(\"Average Accuracy:\", performance)\n",
    "        print(\"---------------------------------------------------\")\n",
    "        \n",
    "        if performance > best_performance:\n",
    "            best_performance = performance\n",
    "            best_lambda = lam\n",
    "            \n",
    "    return best_lambda, best_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c63f6796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.001.....\n",
      "Average Accuracy: 0.9790940766550522\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.03162277660168379.....\n",
      "Average Accuracy: 0.9763066202090593\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.937979094076655\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 31.622776601683793.....\n",
      "Average Accuracy: 0.90801393728223\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1000.0.....\n",
      "Average Accuracy: 0.90801393728223\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.001, 0.9790940766550522)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run on digit = 8\n",
    "lambdas = np.logspace(-3, 3, 5)\n",
    "K_fold_cross_validation(5, 8, lambdas, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e233d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9986062717770036\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.9986062717770036\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9979094076655052\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.9073170731707318\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.9017421602787457\n",
      "---------------------------------------------------\n",
      "Digit  0  has optimal accuracy with lambda =  0.01 . Accuracy =  0.9986062717770036\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9860627177700347\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.9867595818815331\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9707317073170731\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.897560975609756\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.897560975609756\n",
      "---------------------------------------------------\n",
      "Digit  1  has optimal accuracy with lambda =  0.1 . Accuracy =  0.9867595818815331\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9979094076655054\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.9986062717770036\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9867595818815331\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.8975609756097562\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.8961672473867596\n",
      "---------------------------------------------------\n",
      "Digit  2  has optimal accuracy with lambda =  0.1 . Accuracy =  0.9986062717770036\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9867595818815331\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.986759581881533\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9749128919860628\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.897560975609756\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.897560975609756\n",
      "---------------------------------------------------\n",
      "Digit  3  has optimal accuracy with lambda =  0.01 . Accuracy =  0.9867595818815331\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9965156794425087\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.997212543554007\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9923344947735192\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.9066202090592335\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.9059233449477352\n",
      "---------------------------------------------------\n",
      "Digit  4  has optimal accuracy with lambda =  0.1 . Accuracy =  0.997212543554007\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9930313588850174\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.9930313588850174\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9874564459930312\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.8989547038327526\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.8989547038327526\n",
      "---------------------------------------------------\n",
      "Digit  5  has optimal accuracy with lambda =  0.01 . Accuracy =  0.9930313588850174\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9937282229965156\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.994425087108014\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9916376306620209\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.9142857142857143\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.9031358885017422\n",
      "---------------------------------------------------\n",
      "Digit  6  has optimal accuracy with lambda =  0.1 . Accuracy =  0.994425087108014\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9930313588850174\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.9951219512195122\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9888501742160278\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.8989547038327526\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.894773519163763\n",
      "---------------------------------------------------\n",
      "Digit  7  has optimal accuracy with lambda =  0.1 . Accuracy =  0.9951219512195122\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9763066202090593\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.9770034843205575\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.937979094076655\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.90801393728223\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.90801393728223\n",
      "---------------------------------------------------\n",
      "Digit  8  has optimal accuracy with lambda =  0.1 . Accuracy =  0.9770034843205575\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.01.....\n",
      "Average Accuracy: 0.9916376306620208\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 0.1.....\n",
      "Average Accuracy: 0.992334494773519\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 1.0.....\n",
      "Average Accuracy: 0.9616724738675959\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 10.0.....\n",
      "Average Accuracy: 0.8961672473867595\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Evaluating lambda = 100.0.....\n",
      "Average Accuracy: 0.8961672473867595\n",
      "---------------------------------------------------\n",
      "Digit  9  has optimal accuracy with lambda =  0.1 . Accuracy =  0.992334494773519\n"
     ]
    }
   ],
   "source": [
    "# Run 5-fold CV on all digit classifiers\n",
    "lambdas = np.logspace(-2, 2, 5)\n",
    "cv_lams = {}\n",
    "\n",
    "for d in digits:\n",
    "    best_lam, best_acc = K_fold_cross_validation(5, d, lambdas, X_train, y_train)\n",
    "    cv_lams[d] = best_lam\n",
    "    print(\"Digit \", d, \" has optimal accuracy with lambda = \", best_lam, \". Accuracy = \", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "814eac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Optimal Lambda\n",
      "0            0.01\n",
      "1            0.10\n",
      "2            0.10\n",
      "3            0.01\n",
      "4            0.10\n",
      "5            0.01\n",
      "6            0.10\n",
      "7            0.10\n",
      "8            0.10\n",
      "9            0.10\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.from_dict(cv_lams, orient = 'index', columns = ['Optimal Lambda']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7cb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_init = 0.000001\n",
    "tol = 1.0\n",
    "alpha_init = np.zeros(X_train.shape[0])\n",
    "B = 1\n",
    "P = 7\n",
    "K = computegram(kernal, X_train, B, P)\n",
    "\n",
    "for d in digits:\n",
    "    y_train_d = np.where(y_train == d, 1, -1)\n",
    "    svm_d = mysvm(eta_init, tol, alpha_init, K, X_train, y_train_d, cv_lams[d])\n",
    "    classifiers[d] = svm_d[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DATA558] *",
   "language": "python",
   "name": "conda-env-DATA558-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
